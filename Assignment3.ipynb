{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e665ed82",
   "metadata": {},
   "source": [
    "# Identifying the outliers using spectral clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c7931c",
   "metadata": {},
   "source": [
    "# Authors\n",
    "\n",
    "M Anand Krishna - cs22mtech14003\n",
    "\n",
    "K S Akash - cs22mtech11012\n",
    "\n",
    "K Manish - cs22mtech11008\n",
    "\n",
    "A SivaSai - cs22mtech11013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "704d5709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5476b73",
   "metadata": {},
   "source": [
    "### Load the Dataset\n",
    "\n",
    "First, we need to load the dataset into a pandas DataFrame. To do this, we use the `pd.read_csv()` function, which reads a CSV file and returns a DataFrame. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2241b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into a pandas DataFrame (Change the path accordingly)\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "#Normalize\n",
    "scaler = StandardScaler()\n",
    "data_norm = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5febf4ad",
   "metadata": {},
   "source": [
    "### Compute the Similarity Matrix\n",
    "\n",
    "To perform spectral clustering, we first need to compute a similarity matrix, which captures the pairwise similarity between data points. In this case, we use a Gaussian kernel to compute the similarity matrix.\n",
    "\n",
    "The Gaussian kernel is a function that measures the similarity between data points based on their Euclidean distance. It has a parameter `sigma`, which controls the smoothness of the similarity function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7add9abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the similarity matrix using a Gaussian kernel\n",
    "sigma = 1.0\n",
    "similarity_matrix = pairwise_distances(data_norm, metric='euclidean')\n",
    "similarity_matrix = np.exp(-similarity_matrix ** 2 / (2 * sigma ** 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcc7ce4",
   "metadata": {},
   "source": [
    "### Compute the Laplacian Matrix\n",
    "Next, we need to compute the Laplacian matrix, which is a fundamental step in spectral clustering. The Laplacian matrix is derived from the similarity matrix and helps us find the optimal partitioning of the data. To get L, subtract the similarity_matrix from the degree matrix D to obtain the Laplacian matrix L."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8645003",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute the Laplacian matrix\n",
    "D = np.diag(np.sum(similarity_matrix, axis=1))\n",
    "L = D - similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9332a7",
   "metadata": {},
   "source": [
    "### Compute Eigenvectors and Eigenvalues\n",
    "\n",
    "In spectral clustering, we need to compute the eigenvectors and eigenvalues of the Laplacian matrix `L`. The eigenvectors corresponding to the smallest eigenvalues provide us with a lower-dimensional representation of the data, which can be used for clustering.\n",
    "\n",
    "To compute the eigenvectors and eigenvalues, we use NumPy's `linalg.eig` function. We then sort the eigenvalues in ascending order and rearrange the eigenvectors accordingly \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21433c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the eigenvectors and eigenvalues of the Laplacian matrix\n",
    "eigenvalues, eigenvectors = np.linalg.eig(L)\n",
    "idx = eigenvalues.argsort()\n",
    "eigenvalues = eigenvalues[idx]\n",
    "eigenvectors = eigenvectors[:, idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f573bed5",
   "metadata": {},
   "source": [
    "### K-Means Clustering\n",
    "\n",
    "Now that we have computed the eigenvectors of the Laplacian matrix, we can use k-means clustering to partition the data points into clusters. We first select the first `k` eigenvectors, where `k` is the desired number of clusters. Then, we normalize the selected eigenvectors using L2 normalization.\n",
    "\n",
    "Next, we use the `KMeans` class from scikit-learn to fit a k-means model to the eigenvector representation of the data. Finally, we obtain the cluster labels for each data point.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdf2c1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using k-means clustering to cluster the data points in the new eigenvector representation\n",
    "k = 6\n",
    "eigenvectors = eigenvectors[:, :k] \n",
    "eigenvectors = normalize(eigenvectors, axis=1, norm='l2')\n",
    "kmeans_model = KMeans(n_clusters=k, n_init=10).fit(eigenvectors)  # Set n_init explicitly\n",
    "labels = kmeans_model.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99211f6",
   "metadata": {},
   "source": [
    "### Cluster Centroids and Outlier Detection\n",
    "\n",
    "After obtaining the cluster labels, we can compute the cluster centroids, which are the mean of the eigenvector representations of the data points within each cluster. We use the `cluster_centers_` attribute of the fitted `KMeans` model to get the centroids.\n",
    "\n",
    "To identify outliers within each cluster, we first define a threshold multiplier. The threshold for each cluster is set to the mean distance of the data points within the cluster to its centroid, multiplied by the threshold multiplier.\n",
    "\n",
    "We then iterate over the clusters and calculate the distances between the eigenvectors of the data points within the cluster and the cluster centroid. If the distance for any data point exceeds the threshold, it is flagged as an outlier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ec92639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers detected in cluster 0: [3, 37, 59, 68, 82, 206, 232, 249, 251, 309, 314, 361, 408, 432, 527, 533, 689, 720, 1065]\n",
      "Outliers detected in cluster 1: [608, 899]\n"
     ]
    }
   ],
   "source": [
    "# Compute the cluster centroids, handling empty clusters\n",
    "centroids = kmeans_model.cluster_centers_\n",
    "\n",
    "# Define the threshold to flag outliers\n",
    "threshold_multiplier = 1.5\n",
    "\n",
    "# Analyze the clusters to identify outliers, handling empty clusters\n",
    "for label in set(labels):\n",
    "    cluster = data[labels == label]\n",
    "    if len(cluster) == 0:\n",
    "        continue\n",
    "    centroid = centroids[label]\n",
    "    distances = np.linalg.norm(eigenvectors[labels == label] - centroid, axis=1)\n",
    "    mean_distance = np.mean(distances)\n",
    "    threshold = mean_distance * threshold_multiplier\n",
    "    outliers = np.where(distances > threshold)[0]\n",
    "    if len(outliers) > 0:\n",
    "        print(f'Outliers detected in cluster {label}: {list(cluster.iloc[outliers].index)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
